# ğŸ§  MCP Server (Model Compute Paradigm)

A modular, async FastAPI server that dynamically routes incoming ML tasks (e.g. chat, sentiment, recommender, summarization) to pluggable models via a YAML/JSON-backed model registry. Includes retry logic, streaming OpenAI support, async concurrency, Docker support, and unit testing with mocks.

---

## ğŸš€ Features

- âœ… **Async FastAPI** server
- ğŸ§  **Task-based Model Routing** (`chat`, `sentiment`, `recommender`, `summarize`)
- ğŸ“„ **Model Registry** from YAML/JSON
- ğŸ” **Automatic Retry** and **Rate Limit Handling** for APIs
- ğŸ”„ **Streaming Responses** for Chat
- ğŸ§ª **Unit Tests + Mocked API Calls**
- ğŸ³ **Dockerized** for production deployment
- ğŸ“¦ Modular structure, ready for CI/CD

---

## ğŸ— Architecture Overview

```plaintext
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Frontend  â”‚
               â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        YAML/JSON
              â”‚  FastAPI   â”‚â—„â”€â”€â”€â”€â” Model Registry
              â”‚   Server   â”‚     â”‚
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚              â”‚
     â–¼              â–¼              â–¼
 [chat]         [sentiment]   [recommender]
  GPT-4         HF pipeline   stub logic / API


ğŸ›  Setup
ğŸ“¦ Install dependencies
git clone https://github.com/YOUR_USERNAME/mcp-server.git
cd mcp-server

# Optional: create virtualenv
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

pip install -r requirements.txt

â–¶ï¸ Run the server
uvicorn app:app --reload


Access the docs at: http://localhost:8000/docs

ğŸ§ª Running Tests
pytest tests/


Unit tests mock external API calls using unittest.mock.AsyncMock.

ğŸ³ Docker Support
ğŸ”¨ Build image
docker build -t mcp-server .

ğŸš€ Run container
docker run -p 8000:8000 mcp-server

ğŸ§° Example API Request
curl -X POST http://localhost:8000/task \
  -H "Content-Type: application/json" \
  -d '{
        "type": "chat",
        "input": "What are the benefits of restorative yoga?"
      }'

ğŸ” Directory Structure
mcp/
â”œâ”€â”€ app.py                  # FastAPI entry
â”œâ”€â”€ models/                 # ML models (chat, sentiment, etc.)
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ task_router.py      # Task router
â”‚   â””â”€â”€ model_registry.py   # Registry loader
â”œâ”€â”€ registry/models.yaml    # YAML registry of model metadata
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env / .gitignore

âœ… Roadmap
 Async FastAPI - Completed
 Model registry (YAML) - Completed
 Retry & streaming support - Completed
 Unit tests with mocks - Completed
 Docker support - Completed
 CI/CD GitHub Action - Pending
 OAuth/token-based auth - Pending
 HuggingFace model support - Pending
 WebSocket response streaming - Pending

ğŸ¤ Contributing
Pull requests are welcome. For major changes, please open an issue first to discuss what youâ€™d like to change.

ğŸ“„ License
MIT

âœ¨ Author
Built by Sriram Kumar Reddy Challa